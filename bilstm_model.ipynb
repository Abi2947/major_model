{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KNr083XeiHmn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torchvision import transforms , models\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# from urllib import urlopen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igprOaa0iMnV",
        "outputId": "e7dabb55-b1e9-495c-b385-a10250a86c82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d96ST4DyNby7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ac701e-dbd0-4280-806d-8fa83d3b4be1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path\n",
        "data_dir = \"/content/drive/MyDrive/P_datasets\"\n",
        "train_dir =\"/content/drive/MyDrive/P_datasets/train\"\n",
        "test_dir =\"/content/drive/MyDrive/P_datasets/test\"\n",
        "\n",
        "# Define  the transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "#Load the original dataset\n",
        "original_dataset = ImageFolder(root = data_dir, transform = transforms)\n",
        "\n",
        "#Print the class name\n",
        "class_names = original_dataset.classes\n",
        "print(\"Class Name:\", class_names)"
      ],
      "metadata": {
        "id": "cK-FUHxYk9nj",
        "outputId": "14c17b1e-1604-47aa-87d7-4f78ab35e67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Name: ['test', 'train', 'val']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Bidirectional LSTM model\n",
        "class BiLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(BiLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Input gate parameters\n",
        "        self.W_ii = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "        self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_ii = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hi = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        # Forget gate parameters\n",
        "        self.W_if = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "        self.W_hf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_if = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hf = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        # Cell parameters\n",
        "        self.W_ig = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "        self.W_hg = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_ig = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_hg = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        # Output gate parameters\n",
        "        self.W_io = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "        self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        self.b_io = nn.Parameter(torch.Tensor(hidden_size))\n",
        "        self.b_ho = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.data.ndimension() >= 2:\n",
        "                nn.init.xavier_uniform_(p.data)\n",
        "            else:\n",
        "                nn.init.zeros_(p.data)\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        bs, _ = x.size()\n",
        "\n",
        "        h_t, c_t = (torch.zeros(self.hidden_size).to(x.device),\n",
        "                    torch.zeros(self.hidden_size).to(x.device)) if init_states is None else init_states\n",
        "\n",
        "        # Input gate\n",
        "        i_t = torch.sigmoid(x @ self.W_ii.t() + self.b_ii + h_t @ self.W_hi.t() + self.b_hi)\n",
        "        # Forget gate\n",
        "        f_t = torch.sigmoid(x @ self.W_if.t() + self.b_if + h_t @ self.W_hf.t() + self.b_hf)\n",
        "        # Cell gate\n",
        "        g_t = torch.tanh(x @ self.W_ig.t() + self.b_ig + h_t @ self.W_hg.t() + self.b_hg)\n",
        "        # Output gate\n",
        "        o_t = torch.sigmoid(x @ self.W_io.t() + self.b_io + h_t @ self.W_ho.t() + self.b_ho)\n",
        "\n",
        "        c_t = f_t * c_t + i_t * g_t\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        return h_t, c_t\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes, num_layers=1):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.lstm_forward = nn.ModuleList([BiLSTMCell(input_size, hidden_size) for _ in range(num_layers)])\n",
        "        self.lstm_backward = nn.ModuleList([BiLSTMCell(input_size, hidden_size) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        bs, seq_len, _ = x.size()\n",
        "\n",
        "        h_t_forward, c_t_forward = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
        "        h_t_backward, c_t_backward = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            # Forward pass\n",
        "            for layer in range(self.num_layers):\n",
        "                h_t_forward, c_t_forward = self.lstm_forward[layer](x[:, t, :], (h_t_forward, c_t_forward))\n",
        "\n",
        "            # Backward pass\n",
        "            for layer in range(self.num_layers):\n",
        "                h_t_backward, c_t_backward = self.lstm_backward[layer](x[:, seq_len - t - 1, :], (h_t_backward, c_t_backward))\n",
        "\n",
        "        h_t = torch.cat([h_t_forward, h_t_backward], dim=1)\n",
        "        out = self.fc(h_t)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "eI3RDlZFMRUy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "input_size = 64  # Adjustments based on our input data size\n",
        "hidden_size = 128\n",
        "num_classes = 7  # Assuming 7 classes\n",
        "num_layers = 2\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "hRpQDPtai9hy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing and loading\n",
        "train_dataset = ImageFolder(root=train_dir, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]))\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = ImageFolder(root=test_dir, transform=transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "frulWQ1MjAsm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "lr_net = BiLSTM(input_size, hidden_size, num_classes).to(device)\n",
        "model = models.resnet18(pretrained=False, num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "IBy-1OW7jEjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fe244b-bf3a-4df2-c4f2-b9b43afd3c1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model = model.to(device)\n",
        "epochs_list = []\n",
        "tloss = []\n",
        "tacc = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = outputs.max(1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "    epochs_list.append(epoch + 1)\n",
        "    tloss.append(loss.item())\n",
        "    tacc.append(accuracy)\n"
      ],
      "metadata": {
        "id": "koJiwP_zlocS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "vloss = 0.0\n",
        "vacc = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, val_preds = torch.max(outputs, 1)\n",
        "        correct += (val_preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        vloss += loss.item()\n",
        "\n",
        "    # Calculate validation accuracy and loss\n",
        "    vacc = correct / total\n",
        "    vloss /= len(test_loader)\n",
        "\n",
        "    print(f'Validation Loss: {vloss:.4f}, Accuracy: {100 * vacc:.2f}%')\n"
      ],
      "metadata": {
        "id": "XgJndSprlrzR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "2a364163-f26e-4c6d-ed26-0a27c4c21d69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1eb13855c14f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Tranning and validation looss curve over epochs\n",
        "# plt.plot(range(1, num_epochs + 1), train_accuracies[:10], label='Training Accuracy')\n",
        "# plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.title('Training and Validation Accuracy Over Epochs')\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "plt.plot(tloss,'-o')\n",
        "plt.plot(vloss,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Loss')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UdATspwTIvaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Tranning and validation accuracies curve over epochs\n",
        "# plt.plot(epochs_list, loss_list, marker='o')\n",
        "# plt.title('Training Loss Over Epochs')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "plt.plot(tacc,'-o')\n",
        "plt.plot(vacc,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Accuracy')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0GmgvmK_OiSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import matplotlib.pyplot as plt\n",
        "# from torch.utils.data import DataLoader,random_split\n",
        "# from torchvision import transforms\n",
        "# from torchvision.datasets import ImageFolder\n",
        "# from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "# # from urllib import urlopen\n",
        "\n",
        "# # Check if GPU is available\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# print(f'Using device: {device}')\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#    model.cuda()\n",
        "#    inputs = inputs.cuda()\n",
        "#    out = out.cuda()\n",
        "\n",
        "# Dataset path\n",
        "# data_dir = \"/content/drive/MyDrive/P_datasets\"\n",
        "# train_dir =\"/content/drive/MyDrive/P_datasets/train\"\n",
        "# test_dir =\"/content/drive/MyDrive/P_datasets/test\"\n",
        "\n",
        "# # Define  the transformation\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224,224)),\n",
        "#     transforms.ToTensor(),\n",
        "#     ])\n",
        "\n",
        "# #Load the original dataset\n",
        "# original_dataset = ImageFolder(root = data_dir, transform = transforms)\n",
        "\n",
        "# #Print the class name\n",
        "# class_names = original_dataset.classes\n",
        "# print(\"Class Name:\", class_names)\n",
        "\n",
        "# # Define the Bidirectional LSTM model\n",
        "# class BiLSTMCell(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size):\n",
        "#         super(BiLSTMCell, self).__init__()\n",
        "#         self.input_size = input_size\n",
        "#         self.hidden_size = hidden_size\n",
        "\n",
        "#         # Input gate parameters\n",
        "#         self.W_ii = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "#         self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "#         self.b_ii = nn.Parameter(torch.Tensor(hidden_size))\n",
        "#         self.b_hi = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "#         # Forget gate parameters\n",
        "#         self.W_if = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "#         self.W_hf = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "#         self.b_if = nn.Parameter(torch.Tensor(hidden_size))\n",
        "#         self.b_hf = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "#         # Cell parameters\n",
        "#         self.W_ig = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "#         self.W_hg = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "#         self.b_ig = nn.Parameter(torch.Tensor(hidden_size))\n",
        "#         self.b_hg = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "#         # Output gate parameters\n",
        "#         self.W_io = nn.Parameter(torch.Tensor(hidden_size, input_size))\n",
        "#         self.W_ho = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "#         self.b_io = nn.Parameter(torch.Tensor(hidden_size))\n",
        "#         self.b_ho = nn.Parameter(torch.Tensor(hidden_size))\n",
        "\n",
        "#         self.init_weights()\n",
        "\n",
        "#     def init_weights(self):\n",
        "#         for p in self.parameters():\n",
        "#             if p.data.ndimension() >= 2:\n",
        "#                 nn.init.xavier_uniform_(p.data)\n",
        "#             else:\n",
        "#                 nn.init.zeros_(p.data)\n",
        "\n",
        "#     def forward(self, x, init_states=None):\n",
        "#         bs, _ = x.size()\n",
        "\n",
        "#         h_t, c_t = (torch.zeros(self.hidden_size).to(x.device),\n",
        "#                     torch.zeros(self.hidden_size).to(x.device)) if init_states is None else init_states\n",
        "\n",
        "#         # Input gate\n",
        "#         i_t = torch.sigmoid(x @ self.W_ii.t() + self.b_ii + h_t @ self.W_hi.t() + self.b_hi)\n",
        "#         # Forget gate\n",
        "#         f_t = torch.sigmoid(x @ self.W_if.t() + self.b_if + h_t @ self.W_hf.t() + self.b_hf)\n",
        "#         # Cell gate\n",
        "#         g_t = torch.tanh(x @ self.W_ig.t() + self.b_ig + h_t @ self.W_hg.t() + self.b_hg)\n",
        "#         # Output gate\n",
        "#         o_t = torch.sigmoid(x @ self.W_io.t() + self.b_io + h_t @ self.W_ho.t() + self.b_ho)\n",
        "\n",
        "#         c_t = f_t * c_t + i_t * g_t\n",
        "#         h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "#         return h_t, c_t\n",
        "\n",
        "# class BiLSTM(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_classes, num_layers=1):\n",
        "#         super(BiLSTM, self).__init__()\n",
        "\n",
        "#         self.num_layers = num_layers\n",
        "#         self.hidden_size = hidden_size\n",
        "\n",
        "#         self.lstm_forward = nn.ModuleList([BiLSTMCell(input_size, hidden_size) for _ in range(num_layers)])\n",
        "#         self.lstm_backward = nn.ModuleList([BiLSTMCell(input_size, hidden_size) for _ in range(num_layers)])\n",
        "\n",
        "#         self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         bs, seq_len, _ = x.size()\n",
        "\n",
        "#         h_t_forward, c_t_forward = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
        "#         h_t_backward, c_t_backward = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
        "\n",
        "#         for t in range(seq_len):\n",
        "#             # Forward pass\n",
        "#             for layer in range(self.num_layers):\n",
        "#                 h_t_forward, c_t_forward = self.lstm_forward[layer](x[:, t, :], (h_t_forward, c_t_forward))\n",
        "\n",
        "#             # Backward pass\n",
        "#             for layer in range(self.num_layers):\n",
        "#                 h_t_backward, c_t_backward = self.lstm_backward[layer](x[:, seq_len - t - 1, :], (h_t_backward, c_t_backward))\n",
        "\n",
        "#         h_t = torch.cat([h_t_forward, h_t_backward], dim=1)\n",
        "#         out = self.fc(h_t)\n",
        "\n",
        "#         return out\n",
        "\n",
        "\n",
        "# # Define the Bidirectional-LSTM model\n",
        "# class BiLSTM(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_classes, num_layers=1):\n",
        "#         super(BiLSTM, self).__init__()\n",
        "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "#         self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out, _ = self.lstm(x)\n",
        "#         out = self.fc(out[:, -1, :])  # Take the last time step output\n",
        "#         return out\n",
        "\n",
        "# # Hyperparameters\n",
        "# input_size = 64  # Adjustments based on our input data size\n",
        "# hidden_size = 128\n",
        "# num_classes = 7  # Assuming 7 classes\n",
        "# num_layers = 2\n",
        "# learning_rate = 0.001\n",
        "# batch_size = 32\n",
        "# num_epochs = 10\n",
        "\n",
        "# # Data preprocessing and loading\n",
        "# train_dataset = ImageFolder(root = \"train_dir\", transform = transforms.ToTensor())\n",
        "# train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "# test_dataset = ImageFolder(root = \"test_dir\", transform = transforms.ToTensor())\n",
        "# test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "# # Initialize the model, loss function, and optimizer\n",
        "# model = BiLSTM(input_size, hidden_size, num_classes, num_layers)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # Training the model\n",
        "# model = model.to(device)\n",
        "# epochs_list = []\n",
        "# tloss = []\n",
        "# tacc = []\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     total_correct = 0\n",
        "#     total_samples = 0\n",
        "\n",
        "#     for images, labels in train_loader:\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "#         # Forward pass\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Compute accuracy\n",
        "#         _, predicted = outputs.max(1)\n",
        "#         total_correct += (predicted == labels).sum().item()\n",
        "#         total_samples += labels.size(0)\n",
        "\n",
        "#     accuracy = total_correct / total_samples\n",
        "\n",
        "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n",
        "#     epochs_list.append(epoch + 1)\n",
        "#     tloss.append(loss.item())\n",
        "#     tacc.append(accuracy)\n",
        "\n",
        "\n",
        "# # Evaluation on the test set\n",
        "# model.eval()\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# vloss = 0.0\n",
        "# vacc = 0.0\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for images, labels in test_loader:\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         # Compute accuracy\n",
        "#         _, val_preds = torch.max(outputs, 1)\n",
        "#         correct += (val_preds == labels).sum().item()\n",
        "#         total += labels.size(0)\n",
        "\n",
        "#         vloss += loss.item()\n",
        "\n",
        "#     # Calculate validation accuracy and loss\n",
        "#     vacc = correct / total\n",
        "#     vloss /= len(test_loader)\n",
        "\n",
        "#     print(f'Validation Loss: {vloss:.4f}, Accuracy: {100 * vacc:.2f}%')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Plotting Tranning and validation accuracies curve over epochs\n",
        "# plt.plot(tacc,'-o')\n",
        "# plt.plot(vacc,'-o')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.legend(['Train','Valid'])\n",
        "# plt.title('Train vs Valid Accuracy')\n",
        "# plt.grid(True)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# # Plotting Tranning and validation looss curve over epochs\n",
        "# plt.plot(tloss,'-o')\n",
        "# plt.plot(vloss,'-o')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend(['Train','Valid'])\n",
        "# plt.title('Train vs Valid Loss')\n",
        "# plt.grid(True)\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "hMDCn-wk6Ed7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}